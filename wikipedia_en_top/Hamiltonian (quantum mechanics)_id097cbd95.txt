Hamiltonian (quantum mechanics)
In quantum mechanics, the Hamiltonian of a system is an operator corresponding to the total energy of that system, including both kinetic energy and potential energy. Its spectrum, the system's energy spectrum or its set of energy eigenvalues, is the set of possible outcomes obtainable from a measurement of the system's total energy. Due to its close relation to the energy spectrum and time-evolution of a system, it is of fundamental importance in most formulations of quantum theory.
The Hamiltonian is named after William Rowan Hamilton, who developed a revolutionary reformulation of Newtonian mechanics, known as Hamiltonian mechanics, which was historically important to the development of quantum physics. Similar to vector notation, it is typically denoted by $MATH$, where the hat indicates that it is an operator. It can also be written as $MATH$ or $MATH$.
Introduction
The Hamiltonian of a system represents the total energy of the system; that is, the sum of the kinetic and potential energies of all particles associated with the system. The Hamiltonian takes different forms and can be simplified in some cases by taking into account the concrete characteristics of the system under analysis, such as single or several particles in the system, interaction between particles, kind of potential energy, time varying potential or time independent one.
Schrödinger Hamiltonian
One particle
By analogy with classical mechanics, the Hamiltonian is commonly expressed as the sum of operators corresponding to the kinetic and potential energies of a system in the form
where
is the potential energy operator and
is the kinetic energy operator in which $MATH$ is the mass of the particle, the dot denotes the dot product of vectors, and
is the momentum operator where a $MATH$ is the del operator. The dot product of $MATH$ with itself is the Laplacian $MATH$. In three dimensions using Cartesian coordinates the Laplace operator is
Although this is not the technical definition of the Hamiltonian in classical mechanics, it is the form it most commonly takes. Combining these yields the familiar form used in the Schrödinger equation:
which allows one to apply the Hamiltonian to systems described by a wave function $MATH$. This is the approach commonly taken in introductory treatments of quantum mechanics, using the formalism of Schrödinger's wave mechanics.
One can also make substitutions to certain variables to fit specific cases, such as some involving electromagnetic fields.
Many particles
The formalism can be extended to $MATH$ particles:
where
is the potential energy function, now a function of the spatial configuration of the system and time (a particular set of spatial positions at some instant of time defines a configuration) and
is the kinetic energy operator of particle $MATH$, $MATH$ is the gradient for particle $MATH$, and $MATH$ is the Laplacian for particle n:
Combining these yields the Schrödinger Hamiltonian for the $MATH$-particle case:
However, complications can arise in the many-body problem. Since the potential energy depends on the spatial arrangement of the particles, the kinetic energy will also depend on the spatial configuration to conserve energy. The motion due to any one particle will vary due to the motion of all the other particles in the system. For this reason cross terms for kinetic energy may appear in the Hamiltonian; a mix of the gradients for two particles:
where $MATH$ denotes the mass of the collection of particles resulting in this extra kinetic energy. Terms of this form are known as mass polarization terms, and appear in the Hamiltonian of many electron atoms (see below).
For $MATH$ interacting particles, i.e. particles which interact mutually and constitute a many-body situation, the potential energy function $MATH$ is not simply a sum of the separate potentials (and certainly not a product, as this is dimensionally incorrect). The potential energy function can only be written as above: a function of all the spatial positions of each particle.
For non-interacting particles, i.e. particles which do not interact mutually and move independently, the potential of the system is the sum of the separate potential energy for each particle, that is
The general form of the Hamiltonian in this case is:
where the sum is taken over all particles and their corresponding potentials; the result is that the Hamiltonian of the system is the sum of the separate Hamiltonians for each particle. This is an idealized situation—in practice the particles are almost always influenced by some potential, and there are many-body interactions. One illustrative example of a two-body interaction where this form would not apply is for electrostatic potentials due to charged particles, because they interact with each other by Coulomb interaction (electrostatic force), as shown below.
Schrödinger equation
The Hamiltonian generates the time evolution of quantum states. If $MATH$ is the state of the system at time $MATH$, then
This equation is the Schrödinger equation. It takes the same form as the Hamilton–Jacobi equation, which is one of the reasons $MATH$ is also called the Hamiltonian. Given the state at some initial time ($MATH$), we can solve it to obtain the state at any subsequent time. In particular, if $MATH$ is independent of time, then
The exponential operator on the right hand side of the Schrödinger equation is usually defined by the corresponding power series in $MATH$. One might notice that taking polynomials or power series of unbounded operators that are not defined everywhere may not make mathematical sense. Rigorously, to take functions of unbounded operators, a functional calculus is required. In the case of the exponential function, the continuous, or just the holomorphic functional calculus suffices. We note again, however, that for common calculations the physicists' formulation is quite sufficient.
By the *-homomorphism property of the functional calculus, the operator
is a unitary operator. It is the time evolution operator or propagator of a closed quantum system. If the Hamiltonian is time-independent, $MATH$ form a one parameter unitary group (more than a semigroup); this gives rise to the physical principle of detailed balance.
Dirac formalism
However, in the more general formalism of Dirac, the Hamiltonian is typically implemented as an operator on a Hilbert space in the following way:
The eigenkets (eigenvectors) of $MATH$, denoted $MATH$, provide an orthonormal basis for the Hilbert space. The spectrum of allowed energy levels of the system is given by the set of eigenvalues, denoted $MATH$, solving the equation:
Since $MATH$ is a Hermitian operator, the energy is always a real number.
From a mathematically rigorous point of view, care must be taken with the above assumptions. Operators on infinite-dimensional Hilbert spaces need not have eigenvalues (the set of eigenvalues does not necessarily coincide with the spectrum of an operator). However, all routine quantum mechanical calculations can be done using the physical formulation.
Expressions for the Hamiltonian
Following are expressions for the Hamiltonian in a number of situations. Typical ways to classify the expressions are the number of particles, number of dimensions, and the nature of the potential energy function—importantly space and time dependence. Masses are denoted by $MATH$, and charges by $MATH$.
Free particle
The particle is not bound by any potential energy, so the potential is zero and this Hamiltonian is the simplest. For one dimension:
and in higher dimensions:
Constant-potential well
For a particle in a region of constant potential $MATH$ (no dependence on space or time), in one dimension, the Hamiltonian is:
in three dimensions
This applies to the elementary "particle in a box" problem, and step potentials.
Simple harmonic oscillator
For a simple harmonic oscillator in one dimension, the potential varies with position (but not time), according to:
where the angular frequency $MATH$, effective spring constant $MATH$, and mass $MATH$ of the oscillator satisfy:
so the Hamiltonian is:
For three dimensions, this becomes
where the three-dimensional position vector $MATH$ using Cartesian coordinates is $MATH$, its magnitude is
Writing the Hamiltonian out in full shows it is simply the sum of the one-dimensional Hamiltonians in each direction:
Rigid rotor
For a rigid rotor—i.e., system of particles which can rotate freely about any axes, not bound in any potential (such as free molecules with negligible vibrational degrees of freedom, say due to double or triple chemical bonds), the Hamiltonian is:
where $MATH$, $MATH$, and $MATH$ are the moment of inertia components (technically the diagonal elements of the moment of inertia tensor), and $MATH$, $MATH$, and $MATH$ are the total angular momentum operators (components), about the $MATH$, $MATH$, and $MATH$ axes respectively.
Electrostatic or coulomb potential
The Coulomb potential energy for two point charges $MATH$ and $MATH$ (i.e., those that have no spatial extent independently), in three dimensions, is (in SI units—rather than Gaussian units which are frequently used in electromagnetism):
However, this is only the potential for one point charge due to another. If there are many charged particles, each charge has a potential energy due to every other point charge (except itself). For $MATH$ charges, the potential energy of charge $MATH$ due to all other charges is (see also Electrostatic potential energy stored in a configuration of discrete point charges):
where $MATH$ is the electrostatic potential of charge $MATH$ at $MATH$. The total potential of the system is then the sum over $MATH$:
so the Hamiltonian is:
Electric dipole in an electric field
For an electric dipole moment $MATH$ constituting charges of magnitude $MATH$, in a uniform, electrostatic field (time-independent) $MATH$, positioned in one place, the potential is:
the dipole moment itself is the operator
Since the particle is stationary, there is no translational kinetic energy of the dipole, so the Hamiltonian of the dipole is just the potential energy:
Magnetic dipole in a magnetic field
For a magnetic dipole moment $MATH$ in a uniform, magnetostatic field (time-independent) $MATH$, positioned in one place, the potential is:
Since the particle is stationary, there is no translational kinetic energy of the dipole, so the Hamiltonian of the dipole is just the potential energy:
For a spin-1⁄2 particle, the corresponding spin magnetic moment is:
where $MATH$ is the "spin g-factor" (not to be confused with the gyromagnetic ratio), $MATH$ is the electron charge, $MATH$ is the spin operator vector, whose components are the Pauli matrices, hence
Charged particle in an electromagnetic field
For a particle with mass $MATH$ and charge $MATH$ in an electromagnetic field, described by the scalar potential $MATH$ and vector potential $MATH$, there are two parts to the Hamiltonian to substitute for. The canonical momentum operator $MATH$, which includes a contribution from the $MATH$ field and fulfils the canonical commutation relation, must be quantized;
where $MATH$ is the kinetic momentum operator. The quantization prescription reads
so the corresponding kinetic energy operator is
and the potential energy, which is due to the $MATH$ field, is given by
Casting all of these into the Hamiltonian gives
Energy eigenket degeneracy, symmetry, and conservation laws
In many systems, two or more energy eigenstates have the same energy. A simple example of this is a free particle, whose energy eigenstates have wavefunctions that are propagating plane waves. The energy of each of these plane waves is inversely proportional to the square of its wavelength.  A wave propagating in the $MATH$ direction is a different state from one propagating in the $MATH$ direction, but if they have the same wavelength, then their energies will be the same. When this happens, the states are said to be degenerate.
It turns out that degeneracy occurs whenever a nontrivial unitary operator $MATH$ commutes with the Hamiltonian. To see this, suppose that $MATH$ is an energy eigenket. Then $MATH$ is an energy eigenket with the same eigenvalue, since
Since $MATH$ is nontrivial, at least one pair of $MATH$ and $MATH$ must represent distinct states. Therefore, $MATH$ has at least one pair of degenerate energy eigenkets. In the case of the free particle, the unitary operator which produces the symmetry is the rotation operator, which rotates the wavefunctions by some angle while otherwise preserving their shape.
The existence of a symmetry operator implies the existence of a conserved observable. Let $MATH$ be the Hermitian generator of $MATH$:
It is straightforward to show that if $MATH$ commutes with $MATH$, then so does $MATH$:
Therefore,
In obtaining this result, we have used the Schrödinger equation, as well as its dual,
Thus, the expected value of the observable $MATH$ is conserved for any state of the system. In the case of the free particle, the conserved quantity is the angular momentum.
Hamilton's equations
Hamilton's equations in classical Hamiltonian mechanics have a direct analogy in quantum mechanics. Suppose we have a set of basis states $MATH$, which need not necessarily be eigenstates of the energy. For simplicity, we assume that they are discrete, and that they are orthonormal, i.e.,
Note that these basis states are assumed to be independent of time. We will assume that the Hamiltonian is also independent of time.
The instantaneous state of the system at time $MATH$, $MATH$, can be expanded in terms of these basis states:
where
The coefficients $MATH$ are complex variables. We can treat them as coordinates which specify the state of the system, like the position and momentum coordinates which specify a classical system. Like classical coordinates, they are generally not constant in time, and their time dependence gives rise to the time dependence of the system as a whole.
The expectation value of the Hamiltonian of this state, which is also the mean energy, is
where the last step was obtained by expanding $MATH$ in terms of the basis states.
Each $MATH$ actually corresponds to two independent degrees of freedom, since the variable has a real part and an imaginary part. We now perform the following trick: instead of using the real and imaginary parts as the independent variables, we use $MATH$ and its complex conjugate $MATH$. With this choice of independent variables, we can calculate the partial derivative
By applying Schrödinger's equation and using the orthonormality of the basis states, this further reduces to
Similarly, one can show that
If we define "conjugate momentum" variables $MATH$ by
then the above equations become
which is precisely the form of Hamilton's equations, with the $MATH$s as the generalized coordinates, the $MATH$s as the conjugate momenta, and $MATH$ taking the place of the classical Hamiltonian.