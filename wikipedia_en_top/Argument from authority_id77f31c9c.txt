Argument from authority

An argument from authority (argumentum ab auctoritate), also called an appeal to authority, or argumentum ad verecundiam, is a form of argument in which the opinion of an authority on a topic is used as evidence to support an argument. Some consider that it is used in a cogent form if all sides of a discussion agree on the reliability of the authority in the given context, and others consider it to be a fallacy to cite the views of an authority on the discussed topic as a means of supporting an argument.
Overview
Historically, opinion on the appeal to authority has been divided: it is listed as a non-fallacious argument as often as a fallacious argument in various sources, as some hold that it can be a strong or at least valid defeasible argument and others that it is weak or an outright fallacy.
The general form of this type of argument is:
Use in science
Scientific knowledge is best established by evidence and experiment rather than argued through authority as authority has no place in science. Carl Sagan wrote of arguments from authority: "One of the great commandments of science is, 'Mistrust arguments from authority.' ... Too many such arguments have proved too painfully wrong. Authorities must prove their contentions like everybody else." However, countering this it has been argued that science is fundamentally dependent on arguments from authority to progress because "they allow science to avoid forever revisiting the same ground".
One example of the use of the appeal to authority in science dates to 1923, when leading American zoologist Theophilus Painter declared, based on poor data and conflicting observations he had made, that humans had 24 pairs of chromosomes. From the 1920s until 1956, scientists propagated this "fact" based on Painter's authority, despite subsequent counts totaling the correct number of 23. Even textbooks with photos showing 23 pairs incorrectly declared the number to be 24 based on the authority of the then-consensus of 24 pairs.
This seemingly established number generated confirmation bias among researchers, and "most cytologists, expecting to detect Painter's number, virtually always did so". Painter's "influence was so great that many scientists preferred to believe his count over the actual evidence", and scientists who obtained the accurate number modified or discarded their data to agree with Painter's count.
A more recent example involved the paper "When contact changes minds: An experiment on transmission of support for gay equality", published in 2014. The paper was a fraud based on forged data, yet concerns about it were ignored in many cases due to appeals to authority. One analysis of the affair notes that "Over and over again, throughout the scientific community and the media, [co-author Michael] LaCour's impossible-seeming results were treated as truth, in part because of the weight [co-author Donald] Green's name carried". One psychologist stated his reaction to the paper was, "That's very surprising and doesn't fit with a huge literature of evidence. It doesn't sound plausible to me [... but then I pull it up and] I see Don Green is an author. I trust him completely, so I'm no longer doubtful". The forger, LaCour, would use appeals to authority to defend his research: "[...] if his responses sometimes seemed to lack depth when he was pressed for details, his impressive connections often allayed concerns". As one of his partners stated, "When he and I really had a disagreement, he would often rely on the kind of arguments where he'd basically invoke authority, right? He's the one with advanced training, and his adviser is this very high-powered, very experienced person [...] and they know a lot more than we do".
Much like the erroneous chromosome count taking decades to refute until microscopy made the error unmistakable, the person who would go on to debunk this paper "was consistently told by friends and advisers to keep quiet about his concerns lest he earn a reputation as a troublemaker", up until "the very last moment when multiple 'smoking guns' finally appeared." He found that "There was almost no encouragement [...] to probe the hints of weirdness he'd uncovered".
Appeal to false authority
This fallacy is used when a person appeals to a false authority as evidence for a claim. These fallacious arguments from authority are the result of citing a non-authority as an authority. The philosophers Irving Copi and Carl Cohen characterized it as a fallacy "when the appeal is made to parties having no legitimate claim to authority in the matter at hand". Copi stated: "In attempting to make up one's mind on a difficult and complicated question, one may seek to be guided by the judgment of an acknowledged expert who has studied the matter thoroughly. [. . .] This method of argument is in many cases perfectly legitimate. [ . . . ] But when an authority is appealed to for testimony in matters outside the province of that authority's special field, the appeal commits the fallacy of argumentum ad verecundiam ".


In other words, one could say that the premise of the argument does not hold in such a case, rendering the reasoning fallacious.
 An example of the fallacy of appealing to an authority in an unrelated field would be citing Albert Einstein as an authority for a determination on religion when his primary expertise was in physics.
It is also a fallacious ad hominem argument to argue that a person presenting statements lacks authority and thus their arguments do not need to be considered. As appeals to a perceived lack of authority, these types of argument are fallacious for much the same reasons as an appeal to authority.
Other related fallacious arguments assume that a person without status or authority is inherently reliable. For instance, the appeal to poverty is the fallacy of thinking that someone is more likely to be correct because they are poor. When an argument holds that a conclusion is likely to be true precisely because the one who holds or is presenting it lacks authority, it is a fallacious appeal to the common man.
Roots in cognitive bias
Arguments from authority that are based on the idea that a person should conform to the opinion of a perceived authority or authoritative group are rooted in psychological cognitive biases such as the Asch effect. In repeated and modified instances of the Asch conformity experiments, it was found that high-status individuals create a stronger likelihood of a subject agreeing with an obviously false conclusion, despite the subject normally being able to clearly see that the answer was incorrect.
Further, humans have been shown to feel strong emotional pressure to conform to authorities and majority positions. A repeat of the experiments by another group of researchers found that "Participants reported considerable distress under the group pressure", with 59% conforming at least once and agreeing with the clearly incorrect answer, whereas the incorrect answer was much more rarely given when no such pressures were present.
Another study shining light on the psychological basis of the fallacy as it relates to perceived authorities are the Milgram experiments, which demonstrated that people are more likely to go along with something when it is presented by an authority. In a variation of a study where the researchers did not wear lab coats, thus reducing the perceived authority of the tasker, the obedience level dropped to 20% from the original rate, which had been higher than 50%. Obedience is encouraged by reminding the individual of what a perceived authority states and by showing them that their opinion goes against this authority.


Scholars have noted that certain environments can produce an ideal situation for these processes to take hold, giving rise to groupthink. In groupthink, individuals in a group feel inclined to minimize conflict and encourage conformity. Through an appeal to authority, a group member might present that opinion as a consensus and encourage the other group members to engage in groupthink by not disagreeing with this perceived consensus or authority. One paper about the philosophy of mathematics states that, within academia, 
Corporate environments are similarly vulnerable to appeals to perceived authorities and experts leading to groupthink, as are governments and militaries.