Harmonic series (mathematics)
In mathematics, the harmonic series is the infinite series formed by summing all positive unit fractions:
The first $MATH$ terms of the series sum to approximately $MATH$, where $MATH$ is the natural logarithm and $MATH$ is the Euler–Mascheroni constant. Because the logarithm has arbitrarily large values, the harmonic series does not have a finite limit: it is a divergent series. Its divergence was proven in the 14th century by Nicole Oresme using a precursor to the Cauchy condensation test for the convergence of infinite series. It can also be proven to diverge by comparing the sum to an integral, according to the integral test for convergence.
Applications of the harmonic series and its partial sums include Euler's proof that there are infinitely many prime numbers, the analysis of the coupon collector's problem on how many random trials are needed to provide a complete range of responses, the connected components of random graphs, the block-stacking problem on how far over the edge of a table a stack of blocks can be cantilevered, and the average case analysis of the quicksort algorithm.
History
The name of the harmonic series derives from the concept of overtones or harmonics in music: the wavelengths of the overtones of a vibrating string are $MATH$, $MATH$, $MATH$, etc., of the string's fundamental wavelength.  Every term of the harmonic series after the first is the harmonic mean of the neighboring terms, so the terms form a harmonic progression; the phrases harmonic mean and harmonic progression likewise derive from music.
Beyond music, harmonic sequences have also had a certain popularity with architects. This was so particularly in the Baroque period, when architects used them to establish the proportions of floor plans, of elevations, and to establish harmonic relationships between both interior and exterior architectural details of churches and palaces.
The divergence of the harmonic series was first proven in 1350 by Nicole Oresme. Oresme's work, and the contemporaneous work of Richard Swineshead on a different series, marked the first appearance of infinite series other than the geometric series in mathematics. However, this achievement fell into obscurity. Additional proofs were published in the 17th century by Pietro Mengoli and by Jacob Bernoulli. Bernoulli credited his brother Johann Bernoulli for finding the proof, and it was later included in Johann Bernoulli's collected works.
The partial sums of the harmonic series were named harmonic numbers, and given their usual notation $MATH$, in 1968 by Donald Knuth.
Definition and divergence
The harmonic series is the infinite series
in which the terms are all of the positive unit fractions. It is a divergent series: as more terms of the series are included in partial sums of the series, the values of these partial sums grow arbitrarily large, beyond any finite limit. Because it is a divergent series, it should be interpreted as a formal sum, an abstract mathematical expression combining the unit fractions, rather than as something that can be evaluated to a numeric value. There are many different proofs of the divergence of the harmonic series, surveyed in a 2006 paper by S. J. Kifowit and T. A. Stamps.
Two of the best-known are listed below.
Comparison test
One way to prove divergence is to compare the harmonic series with another divergent series, where each denominator is replaced with the next-largest power of two:
Grouping equal terms shows that the second series diverges (because every grouping of convergent series is only convergent):
Because each term of the harmonic series is greater than or equal to the corresponding term of the second series (and the terms are all positive), it follows (by the comparison test) that the harmonic series diverges as well.  The same argument proves more strongly that, for every positive integer $MATH$,
This is the original proof given by Nicole Oresme in around 1350. The Cauchy condensation test is a generalization of this argument.
Integral test
It is possible to prove that the harmonic series diverges by comparing its sum with an improper integral.  Specifically, consider the arrangement of rectangles shown in the figure to the right. Each rectangle is 1 unit wide and $MATH$ units high, so if the harmonic series converged then the total area of the rectangles would be the sum of the harmonic series. The curve $MATH$ stays entirely below the upper boundary of the rectangles, so the area under the curve (in the range of $MATH$ from one to infinity that is covered by rectangles) would be less than the area of the union of the rectangles. However, the area under the curve is given by a divergent improper integral,
Because this integral does not converge, the sum cannot converge either.
Replacing each rectangle by the next one in the sequence would produce a sequence of rectangles whose boundary lies below the curve rather than above it.
This shows that the partial sums of the harmonic series differ from the integral by an amount that is bounded above and below by the unit area of the first rectangle:
Generalizing this argument, any infinite sum of values of a monotone decreasing positive function of $MATH$ (like the harmonic series) has partial sums that are within a bounded distance of the values of the corresponding integrals. Therefore, the sum converges if and only if the integral over the same range of the same function converges. When this equivalence is used to check the convergence of a sum by replacing it with an easier integral, it is known as the integral test for convergence.
Partial sums
Adding the first $MATH$ terms of the harmonic series produces a partial sum, called a harmonic number and denoted $MATH$:
Growth rate
These numbers grow very slowly, with logarithmic growth, as can be seen from the integral test. More precisely, by the Euler–Maclaurin formula,
where $MATH$ is the Euler–Mascheroni constant and $MATH$ which approaches 0 as $MATH$ goes to infinity.
Divisibility
No harmonic numbers are integers, except for $MATH$. One way to prove that $MATH$ is not an integer is to consider the highest power of two $MATH$ in the range from 1 to $MATH$. If $MATH$ is the least common multiple of the numbers from 1 to $MATH$, then
$MATH$ can be rewritten as a sum of fractions with equal denominators 
in which only one of the numerators, $MATH$, is odd and the rest are even, and (when $MATH$) $MATH$ is itself even. Therefore, the result is a fraction with an odd numerator and an even denominator, which cannot be an integer. More strongly, any sequence of consecutive integers has a unique member divisible by a greater power of two than all the other sequence members, from which it follows by the same argument that no two harmonic numbers differ by an integer.
Another proof that the harmonic numbers are not integers observes that the denominator of $MATH$ must be divisible by 
all prime numbers greater than $MATH$, and uses Bertrand's postulate to prove that this set of primes is non-empty. The same argument implies more strongly that, except for $MATH$, $MATH$, and $MATH$, no harmonic number can have a terminating decimal representation. It has been conjectured that every prime number divides the numerators of only a finite subset of the harmonic numbers, but this remains unproven.
Interpolation
The digamma function is defined as the logarithmic derivative of the gamma function
Just as the gamma function provides a continuous interpolation of the factorials, the digamma function provides a continuous interpolation of the harmonic numbers, in the sense that $MATH$.
This equation can be used to extend the definition to harmonic numbers with rational indices.
Applications
Many well-known mathematical problems have solutions involving the harmonic series and its partial sums.
Crossing a desert

The jeep problem or desert-crossing problem is included in a 9th-century problem collection by Alcuin, Propositiones ad Acuendos Juvenes (formulated in terms of camels rather than jeeps), but with an incorrect solution. The problem asks how far into the desert a jeep can travel and return, starting from a base with $MATH$ loads of fuel, by carrying some of the fuel into the desert and leaving it in depots. The optimal solution involves placing depots spaced at distances $MATH$ from the starting point and each other, where $MATH$ is the range of distance that the jeep can travel with a single load of fuel. On each trip out and back from the base, the jeep places one more depot, refueling at the other depots along the way, and placing as much fuel as it can in the newly placed depot while still leaving enough for itself to return to the previous depots and the base. Therefore, the total distance reached on the $MATH$th trip is 
where $MATH$ is the $MATH$th harmonic number. The divergence of the harmonic series implies that crossings of any length are possible with enough fuel.
For instance, for Alcuin's version of the problem, $MATH$: a camel can carry 30 measures of grain and can travel one leuca while eating a single measure, where a leuca is a unit of distance roughly equal to 2.3 kilometres (1.4 mi). The problem has $MATH$: there are 90 measures of grain, enough to supply three trips. For the standard formulation of the desert-crossing problem, it would be possible for the camel to travel $MATH$ leucas and return, by placing a grain storage depot 5 leucas from the base on the first trip and 12.5 leucas from the base on the second trip. However, Alcuin instead asks a slightly different question, how much grain can be transported a distance of 30 leucas without a final return trip, and either strands some camels in the desert or fails to account for the amount of grain consumed by a camel on its return trips.
Stacking blocks
In the block-stacking problem, one must place a pile of $MATH$ identical rectangular blocks, one per layer, so that they hang as far as possible over the edge of a table without falling. The top block can be placed with $MATH$ of its length extending beyond the next lower block. If it is placed in this way, the next block down needs to be placed with at most $MATH$ of its length extending beyond the next lower block, so that the center of mass of the top two block is supported and they do not topple. The third block needs to be placed with at most $MATH$ of its length extending beyond the next lower block, and so on. In this way, it is possible to place the $MATH$ blocks in such a way that they extend $MATH$ lengths beyond the table, where $MATH$ is the $MATH$th harmonic number. The divergence of the harmonic series implies that there is no limit on how far beyond the table the block stack can extend. For stacks with one block per layer, no better solution is possible, but significantly more overhang can be achieved using stacks with more than one block per layer.
Counting primes and divisors

In 1737, Leonhard Euler observed that, as a formal sum, the harmonic series is equal to an Euler product in which each term comes from a prime number: 
 where $MATH$ denotes the set of prime numbers. The left equality comes from applying the distributive law to the product and recognizing the resulting terms as the prime factorizations of the terms in the harmonic series, and the right equality uses the standard formula for a geometric series. The product is divergent, just like the sum, but if it converged one could take logarithms and obtain 
Here, each logarithm is replaced by its Taylor series, and the constant $MATH$ on the right is the evaluation of the convergent series of terms with exponent greater than one. It follows from these manipulations that the sum of reciprocals of primes, on the right hand of this equality, must diverge, for if it converged these steps could be reversed to show that the harmonic series also converges, which it does not. An immediate corollary is that there are infinitely many prime numbers, because a finite sum cannot diverge. Although Euler's work is not considered adequately rigorous by the standards of modern mathematics, it can be made rigorous by taking more care with limits and error bounds. Euler's conclusion that the partial sums of reciprocals of primes grow as a double logarithm of the number of terms has been confirmed by later mathematicians as one of Mertens' theorems, and can be seen as a precursor to the prime number theorem.
Another problem in number theory closely related to the harmonic series concerns the average number of divisors of the numbers in a range from 1 to $MATH$, formalized as the average order of the divisor function,
The operation of rounding each term in the harmonic series to the next smaller integer multiple of $MATH$ causes this average to differ from the harmonic numbers by a small constant, and Peter Gustav Lejeune Dirichlet showed more precisely that the average number of divisors is $MATH$ (expressed in big O notation). Bounding the final error term more precisely remains an open problem, known as Dirichlet's divisor problem.
Collecting coupons
Several common games or recreations involve repeating a random selection from a set of items until all possible choices have been selected; these include the collection of trading cards and the completion of parkrun bingo, in which the goal is to obtain all 60 possible numbers of seconds in the times from a sequence of running events. More serious applications of this problem include sampling all variations of a manufactured product for its quality control, and the connectivity of random graphs. In situations of this form, once there are $MATH$ items remaining to be collected out of a total of $MATH$ equally-likely items, the probability of collecting a new item in a single random choice is $MATH$ and the expected number of random choices needed until a new item is collected is $MATH$. Summing over all values of $MATH$ from $MATH$ down to 1 shows that the total expected number of random choices needed to collect all items is $MATH$, where $MATH$ is the $MATH$th harmonic number.
Analyzing algorithms

The quicksort algorithm for sorting a set of items can be analyzed using the harmonic numbers. The algorithm operates by choosing one item as a "pivot", comparing it to all the others, and recursively sorting the two subsets of items whose comparison places them before the pivot and after the pivot. In either its average-case complexity (with the assumption that all input permutations are equally likely) or in its expected time analysis of worst-case inputs with a random choice of pivot, all of the items are equally likely to be chosen as the pivot. For such cases, one can compute the probability that two items are ever compared with each other, throughout the recursion, as a function of the number of other items that separate them in the final sorted order. If items $MATH$ and $MATH$ are separated by $MATH$ other items, then the algorithm will make a comparison between $MATH$ and $MATH$ only when, as the recursion progresses, it picks $MATH$ or $MATH$ as a pivot before picking any of the other $MATH$ items between them. Because each of these $MATH$ items is equally likely to be chosen first, this happens with probability $MATH$. The total expected number of comparisons, which controls the total running time of the algorithm, can then be calculated by summing these probabilities over all pairs, giving
The divergence of the harmonic series corresponds in this application to the fact that, in the comparison model of sorting used for quicksort, it is not possible to sort in linear time.
Related series
Alternating harmonic series
The series
is known as the alternating harmonic series. It is conditionally convergent by the alternating series test, but not absolutely convergent. Its sum is the natural logarithm of 2.
Explicitly, the asymptotic expansion of the series is
Using alternating signs with only odd unit fractions produces a related series, the Leibniz formula for π
Riemann zeta function
The Riemann zeta function is defined for real $MATH$ by the convergent series
which for $MATH$ would be the harmonic series. It can be extended by analytic continuation to a holomorphic function on all complex numbers except $MATH$, where the extended function has a simple pole. Other important values of the zeta function include $MATH$, the solution to the Basel problem, Apéry's constant $MATH$, proved by Roger Apéry to be an irrational number, and the "critical line" of complex numbers with real part $MATH$, conjectured by the Riemann hypothesis to be the only values other than negative integers where the function can be zero.
Random harmonic series
The random harmonic series is
where the values $MATH$ are independent and identically distributed random variables that take the two values $MATH$ and $MATH$ with equal probability $MATH$. It converges with probability 1, as can be seen by using the Kolmogorov three-series theorem or of the closely related Kolmogorov maximal inequality. The sum of the series is a random variable whose probability density function is close to $MATH$ for values between $MATH$ and $MATH$, and decreases to near-zero for values greater than $MATH$ or less than $MATH$. Intermediate between these ranges, at the values $MATH$, the probability density is $MATH$ for a nonzero but very small value $MATH$.
Depleted harmonic series
The depleted harmonic series where all of the terms in which the digit 9 appears anywhere in the denominator are removed can be shown to converge to the value 22.92067661926415034816.... In fact, when all the terms containing any particular string of digits (in any base) are removed, the series converges.